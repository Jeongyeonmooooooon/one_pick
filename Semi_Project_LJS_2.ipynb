{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import Series, DataFrame\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =pd.read_csv('C:\\\\Users\\Ente_LJS\\\\Anaconda_src\\\\Semi_Project_1pick\\\\train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Target\n",
       "0       4\n",
       "1       4\n",
       "2       4\n",
       "5       4\n",
       "8       4"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_h = df.loc[df[\"parentesco1\"]==1]\n",
    "df_h = df_h.fillna(0)\n",
    "df_y =pd.DataFrame(df_h[\"Target\"])\n",
    "df_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rooms</th>\n",
       "      <th>v14a</th>\n",
       "      <th>refrig</th>\n",
       "      <th>v18q</th>\n",
       "      <th>v18q1</th>\n",
       "      <th>r4h1</th>\n",
       "      <th>r4h2</th>\n",
       "      <th>r4m1</th>\n",
       "      <th>r4m2</th>\n",
       "      <th>r4t1</th>\n",
       "      <th>...</th>\n",
       "      <th>lugar2</th>\n",
       "      <th>lugar3</th>\n",
       "      <th>lugar4</th>\n",
       "      <th>lugar5</th>\n",
       "      <th>lugar6</th>\n",
       "      <th>area1</th>\n",
       "      <th>age</th>\n",
       "      <th>SQBdependency</th>\n",
       "      <th>SQBmeaned</th>\n",
       "      <th>agesq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>64.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>4489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>92</td>\n",
       "      <td>64.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>8464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>1.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>1444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 111 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rooms  v14a  refrig  v18q  v18q1  r4h1  r4h2  r4m1  r4m2  r4t1  ...    \\\n",
       "0      3     1       1     0    0.0     0     1     0     0     0  ...     \n",
       "1      4     1       1     1    1.0     0     1     0     0     0  ...     \n",
       "2      8     1       1     0    0.0     0     0     0     1     0  ...     \n",
       "5      5     1       1     1    1.0     0     2     1     1     1  ...     \n",
       "8      2     1       1     0    0.0     0     1     2     1     2  ...     \n",
       "\n",
       "   lugar2  lugar3  lugar4  lugar5  lugar6  area1  age  SQBdependency  \\\n",
       "0       0       0       0       0       0      1   43            0.0   \n",
       "1       0       0       0       0       0      1   67           64.0   \n",
       "2       0       0       0       0       0      1   92           64.0   \n",
       "5       0       0       0       0       0      1   38            1.0   \n",
       "8       0       0       0       0       0      1   30            1.0   \n",
       "\n",
       "   SQBmeaned  agesq  \n",
       "0      100.0   1849  \n",
       "1      144.0   4489  \n",
       "2      121.0   8464  \n",
       "5      121.0   1444  \n",
       "8      100.0    900  \n",
       "\n",
       "[5 rows x 111 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#불필요한 피쳐들 제거해 x1값 만들기 \n",
    "# age, SQBescolari, SQBage, SQBhogar_total, SQBedjefe, SQBhogar_nin, SQBovercrowding,\n",
    "# SQBdependency, SQBmeaned, agesq\n",
    "\n",
    "#결과값 y에 해당하는 값 삭제 \n",
    "df_x1 = df_h.drop([\"Target\"],1)\n",
    "#세대주성별 교육년수 (논의필요)\n",
    "df_x1 = df_x1.drop([\"edjefa\", \"edjefe\"],1) \n",
    "#중복정보 제거\n",
    "df_x1 = df_x1.drop([\"dependency\",\"female\",\"area2\",\"hacdor\",\"hacapo\",\"bedrooms\",\"r4h3\",\"r4m3\"],1) \n",
    "#수학적으로 의미가 없는 값 제거\n",
    "df_x1 = df_x1.drop([\"Id\",\"SQBescolari\", \"SQBage\", \"SQBhogar_total\", \"SQBedjefe\", \"SQBhogar_nin\", \"SQBovercrowding\",\"idhogar\"],1) \n",
    "#세대주와의 관계열 제거\n",
    "df_x1 = df_x1.drop([\"parentesco1\",\"parentesco2\",\"parentesco3\",\"parentesco4\",\"parentesco5\",\"parentesco6\",\"parentesco7\",\"parentesco8\",\n",
    "                   \"parentesco9\",\"parentesco10\",\"parentesco11\",\"parentesco12\"],1)\n",
    "#집세 임시제거!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "df_x1 = df_x1.drop([\"v2a1\"],1)\n",
    "df_x1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rooms</th>\n",
       "      <th>v14a</th>\n",
       "      <th>refrig</th>\n",
       "      <th>v18q</th>\n",
       "      <th>v18q1</th>\n",
       "      <th>r4h1</th>\n",
       "      <th>r4h2</th>\n",
       "      <th>r4m1</th>\n",
       "      <th>r4m2</th>\n",
       "      <th>escolari</th>\n",
       "      <th>...</th>\n",
       "      <th>lugar3</th>\n",
       "      <th>lugar4</th>\n",
       "      <th>lugar5</th>\n",
       "      <th>lugar6</th>\n",
       "      <th>area1</th>\n",
       "      <th>age</th>\n",
       "      <th>SQBdependency</th>\n",
       "      <th>SQBmeaned</th>\n",
       "      <th>agesq</th>\n",
       "      <th>lent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1849</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>64.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>4489</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>92</td>\n",
       "      <td>64.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>8464</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>1.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>1444</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>900</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rooms  v14a  refrig  v18q  v18q1  r4h1  r4h2  r4m1  r4m2  escolari  ...   \\\n",
       "0      3     1       1     0    0.0     0     1     0     0        10  ...    \n",
       "1      4     1       1     1    1.0     0     1     0     0        12  ...    \n",
       "2      8     1       1     0    0.0     0     0     0     1        11  ...    \n",
       "5      5     1       1     1    1.0     0     2     1     1        11  ...    \n",
       "8      2     1       1     0    0.0     0     1     2     1         9  ...    \n",
       "\n",
       "   lugar3  lugar4  lugar5  lugar6  area1  age  SQBdependency  SQBmeaned  \\\n",
       "0       0       0       0       0      1   43            0.0      100.0   \n",
       "1       0       0       0       0      1   67           64.0      144.0   \n",
       "2       0       0       0       0      1   92           64.0      121.0   \n",
       "5       0       0       0       0      1   38            1.0      121.0   \n",
       "8       0       0       0       0      1   30            1.0      100.0   \n",
       "\n",
       "   agesq  lent  \n",
       "0   1849     0  \n",
       "1   4489     0  \n",
       "2   8464     0  \n",
       "5   1444     0  \n",
       "8    900     0  \n",
       "\n",
       "[5 rows x 107 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#새로운열 추가 \n",
    "# df_x1['rent_to_rooms'] = df_x1['v2a1']/df_x1['rooms']\n",
    "# df_x1['r4t3_to_rooms'] = df_x1['r4t3']/df_x1['rooms']\n",
    "# df_x1['rent_to_r4t3'] = df_x1['v2a1']/df_x1['r4t3']\n",
    "# df_x1['v2a1_to_r4t3'] = df_x1['v2a1']/(df_x1['r4t3'] - df_x1['r4t1'])\n",
    "df_x1['lent'] = df_x1['tamviv']-df_x1['tamhog']\n",
    "\n",
    "#열 생성 이후 불필요한 열 제거 \n",
    "df_x1 = df_x1.drop([\"r4t1\",\"r4t2\",\"r4t3\",\"tamhog\",\"tamviv\"],1) \n",
    "df_x1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y[\"Target\"]=df_y[\"Target\"]-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xavier_init(n_inputs, n_outputs, uniform=True):\n",
    "    if uniform:\n",
    "        # 6 was used in the paper.\n",
    "        init_range = tf.sqrt(6.0 / (n_inputs + n_outputs))\n",
    "        return tf.random_uniform_initializer(-init_range, init_range)\n",
    "    else:\n",
    "        # 3 gives us approximately the same limints as above since this repicks\n",
    "        # values greater than 2 standard deviations from the mean.\n",
    "        stddev = tf.sqrt(3.0 / (n_inputs + n_outputs))\n",
    "        return tf.truncated_normal_initializer(stddev=stddev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxout(inputs, num_units, axis=None):\n",
    "    shape = inputs.get_shape().as_list()\n",
    "    if axis is None:\n",
    "        # Assume that channel is the last dimension\n",
    "        axis = -1\n",
    "    num_channels = shape[axis]\n",
    "    if num_channels % num_units:\n",
    "        raise ValueError('number of features({}) is not a multiple of num_units({})'\n",
    "             .format(num_channels, num_units))\n",
    "    shape[axis] = -1\n",
    "    shape += [num_channels // num_units]\n",
    "    outputs = tf.reduce_max(tf.reshape(inputs, shape), -1, keep_dims=False)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### maxout 적용버전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "x_data = x_data = df_x1\n",
    "sess = tf.Session()\n",
    "y_data = tf.one_hot(df_y, depth = 4).eval(session=sess)\n",
    "y_data = tf.reshape(y_data, shape=[-1,4]).eval(session=sess)\n",
    "print(y_data)\n",
    "tf.set_random_seed(999)  # reproducibility\n",
    "\n",
    "\n",
    "# parameters\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 107])\n",
    "Y = tf.placeholder(tf.float32, [None, 4])\n",
    "\n",
    "W1 = tf.get_variable(\"W1\", shape=[107, 64],\n",
    "                     initializer=xavier_init(107, 64))\n",
    "b1 = tf.Variable(tf.random_normal([64]))\n",
    "L1 = tf.contrib.layers.maxout(tf.matmul(X, W1) + b1, num_units=64)\n",
    "\n",
    "W2 = tf.get_variable(\"W2\", shape=[64, 64],\n",
    "                     initializer=xavier_init(64, 64))\n",
    "b2 = tf.Variable(tf.random_normal([64]))\n",
    "L2 = tf.contrib.layers.maxout(tf.matmul(L1, W2) + b2, num_units=64)\n",
    "\n",
    "W3 = tf.get_variable(\"W3\", shape=[64, 4],\n",
    "                     initializer=xavier_init(64, 4))\n",
    "b3 = tf.Variable(tf.random_normal([4]))\n",
    "hypothesis = tf.matmul(L2, W3) + b3\n",
    "\n",
    "# define cost/loss & optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tanh 적용버전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "x_data = x_data = df_x1\n",
    "sess = tf.Session()\n",
    "y_data = tf.one_hot(df_y, depth = 4).eval(session=sess)\n",
    "y_data = tf.reshape(y_data, shape=[-1,4]).eval(session=sess)\n",
    "print(y_data)\n",
    "tf.set_random_seed(999)  # reproducibility\n",
    "\n",
    "\n",
    "# parameters\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 107])\n",
    "Y = tf.placeholder(tf.float32, [None, 4])\n",
    "\n",
    "W1 = tf.get_variable(\"W1\", shape=[107, 64],\n",
    "                     initializer=xavier_init(107, 64))\n",
    "b1 = tf.Variable(tf.random_normal([64]))\n",
    "L1 = tf.nn.tanh(tf.matmul(X, W1) + b1)\n",
    "\n",
    "W2 = tf.get_variable(\"W2\", shape=[64, 64],\n",
    "                     initializer=xavier_init(64, 64))\n",
    "b2 = tf.Variable(tf.random_normal([64]))\n",
    "L2 = tf.nn.tanh(tf.matmul(L1, W2) + b2)\n",
    "\n",
    "W3 = tf.get_variable(\"W3\", shape=[64, 4],\n",
    "                     initializer=xavier_init(64, 4))\n",
    "b3 = tf.Variable(tf.random_normal([4]))\n",
    "hypothesis = tf.matmul(L2, W3) + b3\n",
    "\n",
    "# define cost/loss & optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### relu 적용버전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "x_data = x_data = df_x1\n",
    "sess = tf.Session()\n",
    "y_data = tf.one_hot(df_y, depth = 4).eval(session=sess)\n",
    "y_data = tf.reshape(y_data, shape=[-1,4]).eval(session=sess)\n",
    "print(y_data)\n",
    "tf.set_random_seed(999)  # reproducibility\n",
    "\n",
    "\n",
    "# parameters\n",
    "learning_rate = 0.002\n",
    "\n",
    "\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 107])\n",
    "Y = tf.placeholder(tf.float32, [None, 4])\n",
    "\n",
    "W1 = tf.get_variable(\"W1\", shape=[107, 64],\n",
    "                     initializer=xavier_init(107, 64))\n",
    "b1 = tf.Variable(tf.random_normal([64]))\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "\n",
    "W2 = tf.get_variable(\"W2\", shape=[64, 64],\n",
    "                     initializer=xavier_init(64, 64))\n",
    "b2 = tf.Variable(tf.random_normal([64]))\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2) + b2)\n",
    "\n",
    "W3 = tf.get_variable(\"W3\", shape=[64, 64],\n",
    "                     initializer=xavier_init(64, 64))\n",
    "b3 = tf.Variable(tf.random_normal([64]))\n",
    "L3 = tf.nn.relu(tf.matmul(L2, W3) + b3)\n",
    "\n",
    "W4 = tf.get_variable(\"W4\", shape=[64, 4],\n",
    "                     initializer=xavier_init(64, 4))\n",
    "b4 = tf.Variable(tf.random_normal([4]))\n",
    "hypothesis = tf.matmul(L3, W4) + b4\n",
    "\n",
    "# define cost/loss & optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실행 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:     0, \t Loss: 66.670, \t Acc: 14.87%\n",
      "Step:     1, \t Loss: 31.265, \t Acc: 12.08%\n",
      "Step:     2, \t Loss: 36.665, \t Acc: 65.29%\n",
      "Step:     3, \t Loss: 49.416, \t Acc: 65.62%\n",
      "Step:     4, \t Loss: 53.836, \t Acc: 65.72%\n",
      "Step:     5, \t Loss: 52.145, \t Acc: 65.72%\n",
      "Step:     6, \t Loss: 46.666, \t Acc: 65.72%\n",
      "Step:     7, \t Loss: 38.307, \t Acc: 65.72%\n",
      "Step:     8, \t Loss: 28.040, \t Acc: 63.17%\n",
      "Step:     9, \t Loss: 42.221, \t Acc: 8.48%\n",
      "Step:    10, \t Loss: 32.272, \t Acc: 8.88%\n",
      "Step:    11, \t Loss: 17.086, \t Acc: 65.42%\n",
      "Step:    12, \t Loss: 16.548, \t Acc: 65.72%\n",
      "Step:    13, \t Loss: 14.001, \t Acc: 65.66%\n",
      "Step:    14, \t Loss: 9.776, \t Acc: 61.65%\n",
      "Step:    15, \t Loss: 8.116, \t Acc: 16.52%\n",
      "Step:    16, \t Loss: 9.009, \t Acc: 15.91%\n",
      "Step:    17, \t Loss: 7.979, \t Acc: 28.39%\n",
      "Step:    18, \t Loss: 9.572, \t Acc: 65.72%\n",
      "Step:    19, \t Loss: 11.839, \t Acc: 65.72%\n",
      "Step:    20, \t Loss: 11.671, \t Acc: 65.72%\n",
      "Step:    21, \t Loss: 9.603, \t Acc: 65.72%\n",
      "Step:    22, \t Loss: 8.097, \t Acc: 28.86%\n",
      "Step:    23, \t Loss: 7.191, \t Acc: 27.68%\n",
      "Step:    24, \t Loss: 6.998, \t Acc: 41.07%\n",
      "Step:    25, \t Loss: 7.589, \t Acc: 64.24%\n",
      "Step:    26, \t Loss: 7.880, \t Acc: 62.53%\n",
      "Step:    27, \t Loss: 7.830, \t Acc: 59.87%\n",
      "Step:    28, \t Loss: 7.340, \t Acc: 65.72%\n",
      "Step:    29, \t Loss: 6.089, \t Acc: 62.80%\n",
      "Step:    30, \t Loss: 4.966, \t Acc: 50.29%\n",
      "Step:    31, \t Loss: 3.457, \t Acc: 60.21%\n",
      "Step:    32, \t Loss: 6.306, \t Acc: 22.97%\n",
      "Step:    33, \t Loss: 3.807, \t Acc: 65.72%\n",
      "Step:    34, \t Loss: 3.802, \t Acc: 65.72%\n",
      "Step:    35, \t Loss: 2.238, \t Acc: 65.76%\n",
      "Step:    36, \t Loss: 3.316, \t Acc: 24.22%\n",
      "Step:    37, \t Loss: 3.855, \t Acc: 27.21%\n",
      "Step:    38, \t Loss: 1.602, \t Acc: 65.72%\n",
      "Step:    39, \t Loss: 2.328, \t Acc: 65.72%\n",
      "Step:    40, \t Loss: 2.655, \t Acc: 47.09%\n",
      "Step:    41, \t Loss: 2.160, \t Acc: 65.69%\n",
      "Step:    42, \t Loss: 1.915, \t Acc: 60.31%\n",
      "Step:    43, \t Loss: 1.222, \t Acc: 65.59%\n",
      "Step:    44, \t Loss: 2.825, \t Acc: 29.53%\n",
      "Step:    45, \t Loss: 1.184, \t Acc: 62.76%\n",
      "Step:    46, \t Loss: 1.708, \t Acc: 65.86%\n",
      "Step:    47, \t Loss: 1.716, \t Acc: 60.44%\n",
      "Step:    48, \t Loss: 1.271, \t Acc: 63.74%\n",
      "Step:    49, \t Loss: 1.379, \t Acc: 52.03%\n",
      "Step:    50, \t Loss: 1.324, \t Acc: 63.81%\n",
      "Step:    51, \t Loss: 1.425, \t Acc: 65.72%\n",
      "Step:    52, \t Loss: 1.048, \t Acc: 61.18%\n",
      "Step:    53, \t Loss: 1.329, \t Acc: 53.38%\n",
      "Step:    54, \t Loss: 1.522, \t Acc: 65.72%\n",
      "Step:    55, \t Loss: 1.462, \t Acc: 63.91%\n",
      "Step:    56, \t Loss: 1.526, \t Acc: 52.61%\n",
      "Step:    57, \t Loss: 1.473, \t Acc: 59.03%\n",
      "Step:    58, \t Loss: 1.835, \t Acc: 65.86%\n",
      "Step:    59, \t Loss: 2.508, \t Acc: 44.77%\n",
      "Step:    60, \t Loss: 2.226, \t Acc: 65.76%\n",
      "Step:    61, \t Loss: 1.651, \t Acc: 65.56%\n",
      "Step:    62, \t Loss: 3.921, \t Acc: 25.60%\n",
      "Step:    63, \t Loss: 1.125, \t Acc: 61.65%\n",
      "Step:    64, \t Loss: 1.804, \t Acc: 65.79%\n",
      "Step:    65, \t Loss: 2.017, \t Acc: 55.90%\n",
      "Step:    66, \t Loss: 1.906, \t Acc: 65.72%\n",
      "Step:    67, \t Loss: 1.509, \t Acc: 62.29%\n",
      "Step:    68, \t Loss: 0.950, \t Acc: 65.02%\n",
      "Step:    69, \t Loss: 2.469, \t Acc: 35.45%\n",
      "Step:    70, \t Loss: 1.669, \t Acc: 65.79%\n",
      "Step:    71, \t Loss: 1.568, \t Acc: 65.76%\n",
      "Step:    72, \t Loss: 2.973, \t Acc: 29.20%\n",
      "Step:    73, \t Loss: 1.342, \t Acc: 65.79%\n",
      "Step:    74, \t Loss: 1.431, \t Acc: 64.78%\n",
      "Step:    75, \t Loss: 2.035, \t Acc: 46.38%\n",
      "Step:    76, \t Loss: 1.727, \t Acc: 65.76%\n",
      "Step:    77, \t Loss: 2.013, \t Acc: 50.76%\n",
      "Step:    78, \t Loss: 1.899, \t Acc: 65.83%\n",
      "Step:    79, \t Loss: 2.646, \t Acc: 42.08%\n",
      "Step:    80, \t Loss: 2.470, \t Acc: 65.83%\n",
      "Step:    81, \t Loss: 2.432, \t Acc: 62.93%\n",
      "Step:    82, \t Loss: 3.055, \t Acc: 46.15%\n",
      "Step:    83, \t Loss: 2.842, \t Acc: 65.83%\n",
      "Step:    84, \t Loss: 2.283, \t Acc: 65.86%\n",
      "Step:    85, \t Loss: 5.071, \t Acc: 19.31%\n",
      "Step:    86, \t Loss: 1.512, \t Acc: 65.89%\n",
      "Step:    87, \t Loss: 1.505, \t Acc: 65.69%\n",
      "Step:    88, \t Loss: 2.526, \t Acc: 39.79%\n",
      "Step:    89, \t Loss: 2.794, \t Acc: 45.14%\n",
      "Step:    90, \t Loss: 4.266, \t Acc: 65.79%\n",
      "Step:    91, \t Loss: 4.904, \t Acc: 65.79%\n",
      "Step:    92, \t Loss: 3.739, \t Acc: 65.83%\n",
      "Step:    93, \t Loss: 1.294, \t Acc: 64.18%\n",
      "Step:    94, \t Loss: 4.649, \t Acc: 18.13%\n",
      "Step:    95, \t Loss: 5.321, \t Acc: 19.88%\n",
      "Step:    96, \t Loss: 2.354, \t Acc: 65.86%\n",
      "Step:    97, \t Loss: 3.788, \t Acc: 65.76%\n",
      "Step:    98, \t Loss: 3.423, \t Acc: 65.76%\n",
      "Step:    99, \t Loss: 4.692, \t Acc: 27.92%\n",
      "Step:  1000, \t Loss: 0.773, \t Acc: 69.79%\n",
      "Step:  2000, \t Loss: 0.804, \t Acc: 69.96%\n",
      "Step:  3000, \t Loss: 0.743, \t Acc: 70.87%\n",
      "Step:  4000, \t Loss: 0.719, \t Acc: 72.12%\n",
      "Step:  5000, \t Loss: 0.696, \t Acc: 72.65%\n",
      "Step:  6000, \t Loss: 0.685, \t Acc: 73.60%\n",
      "Step:  7000, \t Loss: 0.645, \t Acc: 74.74%\n",
      "Step:  8000, \t Loss: 0.618, \t Acc: 76.08%\n",
      "Step:  9000, \t Loss: 0.600, \t Acc: 76.89%\n",
      "Step: 10000, \t Loss: 0.578, \t Acc: 77.60%\n",
      "Step: 11000, \t Loss: 0.556, \t Acc: 78.74%\n",
      "Step: 12000, \t Loss: 0.544, \t Acc: 79.01%\n",
      "Step: 13000, \t Loss: 0.513, \t Acc: 80.39%\n",
      "Step: 14000, \t Loss: 0.484, \t Acc: 81.63%\n",
      "Step: 15000, \t Loss: 0.453, \t Acc: 83.01%\n",
      "Step: 16000, \t Loss: 0.438, \t Acc: 83.48%\n",
      "Step: 17000, \t Loss: 0.385, \t Acc: 85.57%\n",
      "Step: 18000, \t Loss: 0.381, \t Acc: 86.14%\n",
      "Step: 19000, \t Loss: 0.435, \t Acc: 83.82%\n",
      "Step: 20000, \t Loss: 0.545, \t Acc: 81.16%\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(20001):\n",
    "    sess.run(optimizer, feed_dict={X: x_data, Y: y_data})\n",
    "    if step % 1000 == 0 or step < 100:\n",
    "        loss, acc = sess.run([cost, accuracy], feed_dict={\n",
    "                             X: x_data, Y: y_data})\n",
    "        print(\"Step: {:5}, \\t Loss: {:.3f}, \\t Acc: {:.2%}\".format(\n",
    "            step, loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "?df.loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
